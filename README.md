# ðŸ” AI Content Detector

This project detects whether a given text is **AI-generated** or **human-written** using a fine-tuned **DistilBERT** model from Hugging Face.  
It includes both the **training pipeline** and an **interactive web app** built with **Streamlit**.

---

## âœ¨ Features
- âœ… Fine-tuned **DistilBERT** for binary text classification  
- âœ… Detects **AI-generated** vs **Human-written** text  
- âœ… Easy-to-use **Streamlit interface**  
- âœ… Reusable model artifacts (no need to retrain every time)  
- âœ… Built with **modern NLP tools (Hugging Face + PyTorch)**  

---

## ðŸ› ï¸ Tech Stack
- **Python 3.10+**
- **Hugging Face Transformers** â€“ Model & training
- **Datasets** â€“ For handling CSV dataset
- **PyTorch** â€“ Backend deep learning framework
- **Streamlit** â€“ Web app for predictions

---

## ðŸ“‚ Project Structure
CONTENT-DETECTOR/
â”‚
â”œâ”€â”€ artifacts/
â”‚ â””â”€â”€ text_model/ # Saved fine-tuned model + tokenizer
â”‚
â”œâ”€â”€ ai_human_content_detection_dataset.csv # Training dataset
â”‚
â”œâ”€â”€ train.py # Model training script
â”œâ”€â”€ app.py # Streamlit web app
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ README.md # Documentation

---

## ðŸ“ File & Folder Explanation

### 1. **artifacts/**
- Stores **trained models** after running `train.py`.  
- Inside `text_model/`, youâ€™ll find:
  - `config.json` â†’ Model architecture details  
  - `model.safetensors` â†’ Trained weights  
  - `tokenizer.json`, `vocab.txt` â†’ Tokenizer files  

> These files are automatically **loaded by app.py** to make predictions.

---

### 2. **ai_human_content_detection_dataset.csv**
- Dataset used for training.  
- Columns:
  - `prompt` â†’ Input text  
  - `human` â†’ Label (`1 = Human-written`, `0 = AI-generated`)

---

### 3. **train.py**
- Handles the **training pipeline**:
  - Loads dataset from CSV  
  - Tokenizes text using DistilBERT tokenizer  
  - Splits into training & test sets  
  - Fine-tunes DistilBERT for binary classification  
  - Saves trained model into `artifacts/text_model/`

---

### 4. **app.py**
- The **web application** built with **Streamlit**.  
- Features:
  - Loads the fine-tuned model from `artifacts/text_model/`  
  - Provides a **text input box** for users  
  - Returns prediction:
    - âœ… **Human-written**  
    - ðŸš¨ **AI-generated**  
  - Displays **confidence score**

---

### 5. **requirements.txt**
Contains dependencies:
ðŸš€ Running the Project
1. Clone Repository
git clone https://github.com/<your-username>/CONTENT-DETECTOR.git
cd CONTENT-DETECTOR

2. Setup Virtual Environment & Install Dependencies
python -m venv venv
venv\Scripts\activate      # Windows
# or
source venv/bin/activate   # Linux/Mac
pip install -r requirements.txt

3. Train Model (Optional)
python train.py

ðŸ‘‰ Saves fine-tuned model in artifacts/text_model/
4. Run Web App
streamlit run app.py

ðŸ§  Machine Learning Model
Base model: DistilBERT (distilbert-base-uncased)
Fine-tuned for binary classification
0 â†’ AI-generated
1â†’ Human-written
The model is lightweight, fast, and suitable for real-time predictions.
